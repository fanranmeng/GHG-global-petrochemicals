{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculation of per facility ICIS emissions given related IHS processes\n",
    "\n",
    "Assumptions -> Conversion factor used for ICIS facility is mean of conversion factors for all corresponding IHS processes\n",
    "-> For Ethylene, feedstock conversion factor is mean of conversion factors linked to feedstock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# File paths\n",
    "input_path = '../data/'\n",
    "output_path = '../data/combined/'\n",
    "\n",
    "production_file = input_path+'processed/icisFacilityProduction_w_uncertainties.csv'\n",
    "conversion_factor_file = input_path+'combined/processConversionFactors_allgases_allalloc_ammonia.csv'\n",
    "matching_file = input_path+'extra_inputs/all_icis_to_ihs_matches.csv'\n",
    "matching_on = ['PRODUCT', 'ROUTE', 'TECHNOLOGY', 'LICENSOR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "icis_ihs_matches = pd.read_csv(matching_file, index_col=0)\n",
    "facility_production = pd.read_csv(production_file, index_col=0)\n",
    "\n",
    "conv_factors = pd.read_csv(conversion_factor_file)\n",
    "conv_factors = conv_factors.dropna(subset=['ihs_match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facility_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Weight ammonia conversion factor\n",
    "sr_percentage = 0.8\n",
    "\n",
    "ammonia_processes = pd.read_csv('C:/Users\\lukec\\PycharmProjects\\petrochemical-data\\data\\extra_inputs/ammonia_processes_used.csv', index_col=0)\n",
    "grouped_amm = conv_factors[conv_factors['Product']=='AMMONIA'].merge(ammonia_processes, on='ihs_match').groupby('Type').mean()\n",
    "amm_weighted = (1-sr_percentage)*grouped_amm.iloc[0, :]+sr_percentage*grouped_amm.iloc[1, :]\n",
    "\n",
    "amm_df = pd.DataFrame(amm_weighted).transpose().drop(columns=['Total']).astype(float)\n",
    "amm_df['Product'], amm_df['ihs_match'] = 'AMMONIA', 'WEIGHTED AMMONIA'\n",
    "amm_df.index = [3000]\n",
    "conv_factors = pd.concat((conv_factors[conv_factors['Product']!='AMMONIA'], amm_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get Raw Materials columns\n",
    "for gas in ['CO2e_20a', 'CO2e_100a', 'Carbon dioxide', 'Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide', 'Ethane', 'Methane', 'Nitric oxide','Nitrogen fluoride', 'Perfluoropentane','Sulfur hexafluoride', 'Other']:\n",
    "    for col_type in [', mass allocation factor', ', mass allocation sigma', ', energy allocation factor', ', energy allocation sigma', ', economic allocation factor', ', economic allocation sigma']:\n",
    "        if 'energy' in col_type:\n",
    "            columns = ['Feedstock '+gas+col_type, 'Organic chemicals '+gas+col_type, 'Primary chemicals '+gas+col_type]\n",
    "        else:\n",
    "            columns = ['Feedstock '+gas+col_type, 'Organic chemicals '+gas+col_type, 'Primary chemicals '+gas+col_type, 'Other intermediates '+gas+col_type]\n",
    "        conv_factors['Raw Material '+gas+col_type] = conv_factors[columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Filter out outlying possible processes\n",
    "poss_processes = icis_ihs_matches.merge(conv_factors, left_on=['ihs_match'], right_on=['ihs_match'], how='left')\n",
    "\n",
    "# define a function to exclude outliers\n",
    "def exclude_outliers(group, col='ihs_cradle-to-out-gate CO2e_20a, mass allocation factor'):\n",
    "    #print('l'+str(len(group)))\n",
    "    if len(group) > 3:  # only exclude outliers if the group has more than 3 rows\n",
    "        mean = np.mean(group[col])\n",
    "        std = np.std(group[col])\n",
    "        max_distance = std  # maximum distance from the mean to be considered an outlier\n",
    "        distances = np.abs(group[col] - mean)  # calculate distances of each value to the mean\n",
    "        filtered_group = group[distances <= max_distance]  # keep only values within the maximum distance\n",
    "        #print('f'+str(len(filtered_group)))\n",
    "        if len(filtered_group) < 3:  # if less than 3 rows remain, take the 3 closest to the mean\n",
    "            group['dist'] = np.abs(group[col] - mean)\n",
    "            closest_rows = group.nsmallest(3, 'dist', keep='all')\n",
    "            print(closest_rows)\n",
    "            return closest_rows.drop(columns=['dist'])\n",
    "        else:\n",
    "            return filtered_group\n",
    "    else:\n",
    "        return group\n",
    "\n",
    "cols = ['PRODUCT', 'ROUTE', 'TECHNOLOGY', 'LICENSOR']\n",
    "keep_rows = poss_processes[cols+['ihs_match', 'ihs_cradle-to-out-gate CO2e_20a, mass allocation factor']].groupby(cols).apply(exclude_outliers)\n",
    "filt_processes = poss_processes.iloc[list(keep_rows.index.get_level_values(4))].reset_index(drop=True)\n",
    "icis_ihs_matches = filt_processes[['ihs_match']+cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Add IFA production\n",
    "fert_production_file = input_path+'extracted/IFA_production_w_uncertainties.csv'\n",
    "ifa_production = pd.read_csv(fert_production_file)\n",
    "\n",
    "name_conversions = {\n",
    "    'NH3': 'AMMONIA',\n",
    "    'AN': 'AMMONIUM NITRATE',\n",
    "    'Ammonium nitrate (33.5-0-0) granulated': 'AMMONIUM NITRATE',\n",
    "    'AS': 'AMMONIUM SULPHATE',\n",
    "    'CAN': 'CALCIUM AMMONIUM NITRATE',\n",
    "    'Calcium ammonium nitrate (27-0-0)': 'CALCIUM AMMONIUM NITRATE',\n",
    "    'Urea (46-0-0)': 'UREA'\n",
    "}\n",
    "\n",
    "ifa_ihs_matches = {\n",
    "    'AMMONIA':'AMMONIA',\n",
    "    'AMMONIUM NITRATE': 'AMMONIUM NITRATE FERTILIZER',\n",
    "    'AMMONIUM SULPHATE': 'HYDROXYLAMMONIUM SULFATE',\n",
    "    'CALCIUM AMMONIUM NITRATE':'AMMONIUM NITRATE FERTILIZER',\n",
    "    'UREA': 'UREA, AGRICULTURAL GRADE'\n",
    "}\n",
    "\n",
    "ifa_production['PRODUCT'] = ifa_production['PRODUCT'].replace(name_conversions)\n",
    "ifa_production.rename(columns={'Region':'COUNTRY/TERRITORY'}, inplace=True)\n",
    "ifa_production['Conv_name'] = ifa_production['PRODUCT'].replace(ifa_ihs_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Exclude outliers\n",
    "poss_ifa = ifa_production.merge(conv_factors, left_on='Conv_name', right_on='Product', how='left').drop(columns=['Conv_name', 'Product'])\n",
    "cols = ['PRODUCT']\n",
    "ifa_years = [str(i) for i in range(1978,2051)]\n",
    "keep_rows = poss_ifa[cols+['ihs_match', 'ihs_cradle-to-out-gate CO2e_20a, mass allocation factor']].groupby(cols).apply(exclude_outliers)\n",
    "filt_ifa = poss_ifa.iloc[list(keep_rows.index.get_level_values(1))].reset_index(drop=True)\n",
    "ifa_conversion = filt_ifa[['COUNTRY/TERRITORY']+ifa_years+cols+[i+'_sigma' for i in ifa_years]+['ihs_match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facility_conversion = facility_production.merge(icis_ihs_matches, on=matching_on, how='left')\n",
    "facility_conversion = pd.concat((facility_conversion, ifa_conversion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print out Products with no IHS match\n",
    "facility_conversion[facility_conversion['ihs_match'].isna()][['PRODUCT','ROUTE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### -> Misses products with no IHS match\n",
    "facility_conversion_orig = facility_conversion.dropna(subset=['ihs_match']).merge(conv_factors, on=['ihs_match'], how='left')\n",
    "facility_conversion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate emissions by combining production with conversion factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Take average of CM and EI conversion factors\n",
    "\n",
    "emission_val_cols_all = [['CO2e_20a', 'CO2e_100a', 'Carbon dioxide'], ['Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide'], ['Ethane', 'Methane', 'Nitric oxide'], ['Nitrogen fluoride', 'Perfluoropentane'], ['Sulfur hexafluoride', 'Other']]\n",
    "\n",
    "for i, emission_val_cols in enumerate(emission_val_cols_all[1:]):\n",
    "    emission_val_cols_sigma = [col + '_sigma' for col in emission_val_cols]\n",
    "    facility_conversion = facility_conversion_orig.copy()\n",
    "\n",
    "    #for i, emission_val_cols in enumerate(emission_val_cols_all):\n",
    "    emission_val_cols_sigma = [col + '_sigma' for col in emission_val_cols]\n",
    "    facility_conversion = facility_conversion_orig.copy()\n",
    "\n",
    "    for column, col_sigma in zip(emission_val_cols, emission_val_cols_sigma):\n",
    "        facility_conversion['combined_' + column] = np.nanmean([facility_conversion['ei_' + column + '_conv_factor'], facility_conversion['cm_' + column + '_conv_factor']], axis=0)\n",
    "        facility_conversion['combined_' + col_sigma] = np.nanmean([facility_conversion['ei_' + column + '_conv_factor_sigma'], facility_conversion['cm_' + column + '_conv_factor_sigma']], axis=0)\n",
    "\n",
    "    facility_conversion = facility_conversion[facility_conversion.columns[['ei' not in col and 'cm' not in col for col in facility_conversion.columns]]]\n",
    "\n",
    "    facility_conversion.columns = [i.replace(', mass allocation ','_').replace('_factor','') for i in facility_conversion.columns]\n",
    "\n",
    "    facility_conversion.rename(columns={'ihs_match':'PROCESS'}, inplace=True)\n",
    "\n",
    "    facility_conversion.columns = [i.replace(',  allocation ','_').replace('_factor','') for i in facility_conversion.columns]\n",
    "\n",
    "    # Calculate facility emissions for\n",
    "    dbs = ['combined_', 'ihs_cradle-to-out-gate ', 'Feedstock ', 'Organic chemicals ', 'Primary chemicals ', 'Other intermediates ', 'Indirect Utilities ', 'Direct Utilities ', 'Direct Process ', 'Electricity ', 'Raw Material ']\n",
    "    names = ['EI & CM', 'IHS CtOG', 'Feedstock', 'Organic chemicals', 'Primary chemicals', 'Other intermediates', 'Indirect Utilities', 'Direct Utilities', 'Direct Process', 'Electricity', 'Raw Material']\n",
    "\n",
    "    # Create base dataframe to use\n",
    "    years = [str(i) for i in range(1978, 2051)]\n",
    "    years_sigma = [year+'_sigma' for year in years]\n",
    "    base_columns = ['PRODUCT', 'COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#',\n",
    "           'ROUTE', 'TECHNOLOGY', 'LICENSOR', 'START_YR', 'COMPLEX', 'LATITUDE', 'LONGITUDE', 'PROCESS'] + years + years_sigma\n",
    "    base_df = facility_conversion[base_columns]\n",
    "\n",
    "    facility_emissions = pd.DataFrame()\n",
    "    for db, name in tqdm(zip(dbs, names)):\n",
    "        for gas in tqdm(emission_val_cols):\n",
    "            df = base_df.copy()\n",
    "            df[years] = df[years].multiply(facility_conversion[db+gas], axis='index')\n",
    "            ## Incorrect error propagation here\n",
    "            df[years_sigma] = df[years_sigma].multiply(facility_conversion[db+gas+'_sigma'], axis='index')\n",
    "            df['Gas'] = gas\n",
    "            df['Type'] = name\n",
    "            facility_emissions = pd.concat((facility_emissions, df), axis = 0)\n",
    "\n",
    "    facility_emissions.to_parquet(output_path+'icisFacilityEmissions_allIhsProcesses_w_uncertainties_amm'+str(i+1)+'.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endings = [str(i) for i in range(5)]\n",
    "years = [str(i) for i in range(1978, 2051)]\n",
    "years_sigma = [year+'_sigma' for year in years]\n",
    "\n",
    "mean_aggregated = pd.DataFrame()\n",
    "\n",
    "for end in tqdm(endings):\n",
    "    facility_emissions = pd.read_parquet(output_path+'icisFacilityEmissions_allIhsProcesses_w_uncertainties_amm'+end+'.parquet')\n",
    "    print('0')\n",
    "\n",
    "    facility_emissions[facility_emissions.columns[:13]] = facility_emissions[facility_emissions.columns[:13]].fillna('n.a.')\n",
    "    # Take mean of possible emissions given different possible technologies for each facility\n",
    "    aggregated_emissions = facility_emissions.groupby(list(facility_emissions.columns[:13])+['Gas','Type']).mean()\n",
    "    print('1')\n",
    "\n",
    "    ## Get technology uncertainty by taking stdev\n",
    "    stdevs = facility_emissions[list(facility_emissions.columns[:13])+['Gas','Type']+years].groupby(list(facility_emissions.columns[:13])+['Gas','Type']).agg(np.std)\n",
    "    print('5')\n",
    "\n",
    "    # Keep largest uncertainty between technologies and others\n",
    "    aggregated_emissions[years_sigma] = np.maximum(stdevs.fillna(0).values, aggregated_emissions.fillna(0)[years_sigma].values)\n",
    "\n",
    "    mean_aggregated = pd.concat((mean_aggregated, aggregated_emissions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#mean_aggregated = mean_aggregated.reset_index()\n",
    "#mean_aggregated.drop(columns=['index'], inplace=True)\n",
    "mean_aggregated[mean_aggregated.columns[:15]] = mean_aggregated[mean_aggregated.columns[:15]].astype(str)\n",
    "\n",
    "mean_aggregated.to_parquet(output_path+'icisFacilityEmissions_ihsMean_w_uncertainties_allgases_amm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del facility_emissions\n",
    "del mean_aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Weighted average for Ethylene production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read in individual facilities\n",
    "facility_production = pd.read_csv(production_file, index_col=0)\n",
    "eth_prod = facility_production[facility_production['PRODUCT']=='ETHYLENE'].reset_index(drop=True)\n",
    "conv_factors = pd.read_csv(conversion_factor_file)\n",
    "eth_conv = conv_factors[conv_factors['Product']=='ETHYLENE'].reset_index(drop=True)\n",
    "\n",
    "# Ethylene feedstocks\n",
    "feedstocks = pd.read_csv(input_path+'extracted/icisEthyleneFeedstocks_1978-2050.csv', index_col=0, header=[0,1])\n",
    "feedstock_types = pd.read_csv(input_path+'extra_inputs/feedstock_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get emissions for each feedstock\n",
    "years = list(map(str, list(range(1978, 2051))))\n",
    "\n",
    "eth_prod = facility_production[facility_production['PRODUCT']=='ETHYLENE']\n",
    "feedstock_matches = feedstocks.merge(eth_prod, how='left', left_on=list(feedstocks.columns[:6]),\n",
    "                                     right_on=['COUNTRY/TERRITORY','STATE','COMPANY','SITE', '#', 'START_YR'])\n",
    "\n",
    "capacity_cols = [i for i in feedstock_matches.columns if 'CAPACITY' in str(i)]\n",
    "\n",
    "for col, year in zip(capacity_cols, years):\n",
    "    feedstock_matches[col] = feedstock_matches[year]\n",
    "\n",
    "feedstock_matches.drop(columns=list(facility_production.columns), inplace=True)\n",
    "feedstock_matches.columns = pd.MultiIndex.from_tuples((feedstock_matches.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del feedstocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feedstock_vals = feedstock_matches.copy()\n",
    "for year in years:\n",
    "    df = feedstock_vals[year]\n",
    "    df['CAPACITY'] = df['CAPACITY'].apply(lambda x: re.sub(\"[^0-9.]\", \"0\", str(x))).astype(float)\n",
    "    df[df.columns[1:]] = df[df.columns[1:]].multiply(df['CAPACITY']/100, axis='index')\n",
    "    feedstock_vals[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def exclude_outliers(group, col='ihs_cradle-to-out-gate CO2e_20a, mass allocation factor'):\n",
    "    #print('l'+str(len(group)))\n",
    "    if len(group) > 3:  # only exclude outliers if the group has more than 3 rows\n",
    "        mean = np.mean(group[col])\n",
    "        std = np.std(group[col])\n",
    "        max_distance = std  # maximum distance from the mean to be considered an outlier\n",
    "        distances = np.abs(group[col] - mean)  # calculate distances of each value to the mean\n",
    "        filtered_group = group[distances <= max_distance]  # keep only values within the maximum distance\n",
    "        #print('f'+str(len(filtered_group)))\n",
    "        if len(filtered_group) < 3:  # if less than 3 rows remain, take the 3 closest to the mean\n",
    "            group['dist'] = np.abs(group[col] - mean)\n",
    "            closest_rows = group.nsmallest(3, 'dist', keep='all')\n",
    "            print(closest_rows)\n",
    "            return closest_rows.drop(columns=['dist'])\n",
    "        else:\n",
    "            return filtered_group\n",
    "    else:\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feedstock_emissions = eth_conv.merge(feedstock_types, on='ihs_match', how='left')\n",
    "\n",
    "# Take mean of possible emissions given different possible technologuies for each facility\n",
    "aggregated_emissions = feedstock_emissions.groupby(['Feedstock']).mean()\n",
    "\n",
    "#col = 'ihs_cradle-to-out-gate CO2e_100a,  allocation factor'\n",
    "keep_match_locs = feedstock_emissions.groupby('Feedstock').apply(exclude_outliers).drop(columns=['Feedstock']).reset_index()['level_1']\n",
    "keep_matches = eth_conv.loc[keep_match_locs]\n",
    "keep_rows = feedstock_emissions['ihs_match'].isin(keep_matches['ihs_match'])\n",
    "feedstock_emissions = feedstock_emissions[keep_rows]\n",
    "\n",
    "filt_agg = feedstock_emissions.groupby(['Feedstock']).mean()\n",
    "\n",
    "## Get technology uncertainty by taking stdev\n",
    "stdevs = feedstock_emissions[['Feedstock']+[i for i in feedstock_emissions.columns if 'ihs' in i and 'sigma' not in i]].groupby(['Feedstock']).agg(np.std)\n",
    "#\n",
    "# # Keep largest uncertainty between technologies and others\n",
    "years_sigma = [i for i in feedstock_emissions.columns if 'ihs' in i and 'sigma' in i]\n",
    "filt_agg[years_sigma] = np.abs((stdevs.fillna(0).values-filt_agg.fillna(0)[years_sigma].values)/2)+np.minimum(stdevs.fillna(0).values, filt_agg.fillna(0)[years_sigma].values)#np.maximum(stdevs.fillna(0).values, filt_agg.fillna(0)[years_sigma].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# filt_agg.to_csv('C:/Users\\lukec\\PycharmProjects\\petrochemical-data\\data\\processed/ethylene_conversion_factors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filt_agg = pd.read_csv('C:/Users\\lukec\\PycharmProjects\\petrochemical-data\\data\\processed/ethylene_conversion_factors.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Apply emissions to each facility\n",
    "blank = feedstock_vals[feedstock_vals.columns[:7]]\n",
    "blank.columns = list(blank.columns.droplevel(1))\n",
    "conversions = filt_agg.columns[['allocation' in name for name in filt_agg.columns]]\n",
    "\n",
    "for conversion in tqdm(conversions):\n",
    "    fs_ems = filt_agg[conversion]\n",
    "    each_conv = pd.DataFrame()\n",
    "    for year in years:\n",
    "        df = feedstock_vals[year]\n",
    "        for fs in df.columns[1:]:\n",
    "            df[fs] = df[fs]*fs_ems.loc[fs]\n",
    "        yearly = blank.copy()\n",
    "        yearly['Year'] = year\n",
    "        yearly[conversion] = np.sum(df[df.columns[1:]].values, axis=1)\n",
    "        each_conv = pd.concat((each_conv,yearly), axis=0)\n",
    "    conv_emissions = pd.concat((blank, each_conv.pivot(columns=['Year'], values=conversion)), axis=1)\n",
    "    conv_emissions['conversion'] = conversion\n",
    "    if conversion != conversions[0]:\n",
    "        ethylene_ems = pd.concat((ethylene_ems, conv_emissions), axis=0)#.merge(each_conv, on=list(each_conv.columns[:8]), how='left')\n",
    "    else: ethylene_ems = conv_emissions.copy()\n",
    "\n",
    "ethylene_ems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert output to facility_emissions format\n",
    "ethylene_conv = ethylene_ems.copy()\n",
    "ethylene_conv['conversion'] = [i.replace(',  allocation ','_').replace('_factor','') for i in ethylene_conv['conversion']]\n",
    "#ethylene_conv.columns = [i.replace(',  allocation ','_').replace('_factor','') for i in ethylene_conv.columns]\n",
    "\n",
    "dbs = ['ihs_cradle-to-out-gate ', 'Feedstock ', 'Organic chemicals ', 'Primary chemicals ', 'Other intermediates ', 'Direct Utilities ', 'Indirect Utilities ', 'Direct Process ', 'Electricity ', 'Raw Material ']\n",
    "names = ['IHS CtOG', 'Feedstock', 'Organic chemicals', 'Primary chemicals', 'Other intermediates', 'Direct Utilities', 'Indirect Utilities', 'Direct Process', 'Electricity', 'Raw Material']\n",
    "# dbs = ['ihs_cradle-to-out-gate ', 'Raw Material ', 'Indirect Utilities ', 'Direct Utilities ', 'Direct Process ', 'Electricity ']\n",
    "# names = ['IHS CtOG', 'Raw Material', 'Indirect Utilities', 'Direct Utilities', 'Direct Process', 'Electricity']\n",
    "emission_val_cols = ['CO2e_20a', 'CO2e_100a', 'Carbon dioxide', 'Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide', 'Ethane', 'Methane', 'Nitric oxide', 'Nitrogen fluoride', 'Perfluoropentane', 'Sulfur hexafluoride', 'Other']\n",
    "\n",
    "base_cols = list(ethylene_conv.columns[:7])\n",
    "\n",
    "ethylene_vals = pd.DataFrame()\n",
    "ethylene_sigmas = pd.DataFrame()\n",
    "#\n",
    "for db, name in zip(dbs, names):\n",
    "    for gas in emission_val_cols:\n",
    "        df = ethylene_conv[ethylene_conv['conversion']==db+gas]\n",
    "        df['Gas'] = gas\n",
    "        df['Type'] = name\n",
    "        ethylene_vals = pd.concat((ethylene_vals, df), axis = 0)\n",
    "\n",
    "        df_sigma = ethylene_conv[ethylene_conv['conversion']==db+gas+'_sigma']\n",
    "        df_sigma['Gas'] = gas\n",
    "        df_sigma['Type'] = name\n",
    "        ethylene_sigmas = pd.concat((ethylene_sigmas, df_sigma), axis = 0)\n",
    "\n",
    "ethylene_weighted = ethylene_vals.merge(ethylene_sigmas, on=base_cols+['Gas', 'Type'], how='left', suffixes=('','_sigma')).reset_index()\n",
    "#\n",
    "# #ethylene_weighted.columns.name = None\n",
    "ethylene_weighted = ethylene_weighted.fillna(0).drop(columns=['conversion', 'conversion_sigma', 'index'])\n",
    "\n",
    "ethylene_weighted[['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas']] = ethylene_weighted[['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Update ethylene values in facility emissions database\n",
    "facility_emissions = pd.read_parquet(output_path+'icisFacilityEmissions_ihsMean_w_uncertainties_allgases_amm.parquet')\n",
    "\n",
    "eth_ems = facility_emissions[facility_emissions['PRODUCT']=='ETHYLENE']\n",
    "\n",
    "emissions_merged = eth_ems.merge(ethylene_weighted, on=['COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#', 'START_YR', 'Type', 'Gas'], how='left', suffixes=('_old',''))\n",
    "\n",
    "years = [str(i) for i in range(1978, 2051)]\n",
    "years_sigma = [year+'_sigma' for year in years]\n",
    "\n",
    "for year, uncert in zip(years, years_sigma):\n",
    "    emissions_merged[year] = emissions_merged[year].fillna(emissions_merged[year+'_old'])\n",
    "    emissions_merged[uncert] = emissions_merged[uncert].fillna(emissions_merged[uncert+'_old'])\n",
    "\n",
    "eth_emissions_update = emissions_merged.drop(columns=list(emissions_merged.columns[['_old' in i for i in emissions_merged.columns]]) + ['START_MO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del facility_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_update = pd.concat((facility_emissions[facility_emissions['PRODUCT']!='ETHYLENE'], eth_emissions_update), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del ethylene_ems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_update[years_sigma] = full_update[years_sigma].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_update.sort_values(list(full_update.columns[:15])).to_parquet(output_path+'icisFacilityEmissions_ihsWeighted_w_uncertainties_allgases_amm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_df(df, cols, filters):\n",
    "    for col, filt in zip(cols, filters):\n",
    "        df = df[[i in filt for i in df[col]]]\n",
    "    return df\n",
    "\n",
    "filtered = filter_df(full_update, ['Gas'], [['CO2e_100a']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered = filter_df(filtered, ['Type'], [['Direct Process', 'Direct Utilities', 'Indirect Utilities', 'Feedstock', 'Organic chemicals', 'Primary chemicals', 'Other intermediates']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filtered['2020'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filter_df(filtered, ['PRODUCT'], [['AMMONIA']])['2020'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Utility functions\n",
    "def uncertainty_propagation(calc:str, x:float, dx:float, y:float=1, dy:float=0, z:float=1, propagation_type:str='simple') -> float:\n",
    "    if calc == 'mult':\n",
    "        xdiv = np.divide(dx, x, out=np.zeros_like(dx), where=x!=0)\n",
    "        ydiv = np.divide(dy, y, out=np.zeros_like(dy), where=y!=0)\n",
    "        if propagation_type == 'simple':\n",
    "            return (xdiv + ydiv)*z\n",
    "        elif propagation_type == 'stdev':\n",
    "            return np.sqrt(pow(xdiv,2) + pow(ydiv,2))*z\n",
    "        else: Exception('Specified propagation_type not recognised.')\n",
    "\n",
    "    elif calc == 'add':\n",
    "        if propagation_type == 'simple':\n",
    "            return abs(dx)+abs(dy)\n",
    "        elif propagation_type == 'stdev':\n",
    "            return np.sqrt(pow(dx,2) + pow(dy,2))\n",
    "        else: Exception('Specified propagation_type not recognised.')\n",
    "    else: Exception('Please specify calc of propagation')#%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# All possible facility emissions given different processes for making same product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facility_match = facility_conversion[list(facility_conversion.columns[:list(facility_conversion.columns).index('PROCESS')+2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sort_col = 'ihs_cradle-to-out-gate CO2e_20a,  allocation factor'\n",
    "# min_conv_factors = conv_factors.sort_values(['Product', sort_col]).groupby('Product').head(1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "facility_min_type = facility_match.drop(columns='PROCESS').merge(conv_factors, on='Product', how='left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emission_val_cols = ['CO2e_20a', 'CO2e_100a']#, 'Carbon dioxide', 'Carbon monoxide', 'Chloroform', 'Dinitrogen monoxide', 'Ethane', 'Methane', 'Nitric oxide', 'Nitrogen fluoride', 'Perfluoropentane', 'Sulfur hexafluoride', 'Other']\n",
    "emission_val_cols_sigma = [col + '_sigma' for col in emission_val_cols]\n",
    "\n",
    "for column, col_sigma in zip(emission_val_cols, emission_val_cols_sigma):\n",
    "    facility_min_type['combined_' + column] = np.nanmean([facility_min_type['ei_' + column + '_cradle-to-gate'], facility_min_type['cm_' + column + '_cradle-to-gate']], axis=0)\n",
    "    facility_min_type['combined_' + col_sigma] = np.nanmean([facility_min_type['ei_' + column + '_cradle-to-gate_sigma'], facility_min_type['cm_' + column + '_cradle-to-gate_sigma']], axis=0)\n",
    "\n",
    "facility_min_type = facility_min_type[facility_min_type.columns[['ei' not in col and 'cm' not in col for col in facility_min_type.columns]]]\n",
    "\n",
    "facility_min_type.columns = [i.replace(',  allocation factor','').replace(',  allocation sigma','_sigma') for i in facility_min_type.columns]\n",
    "\n",
    "facility_min_type.rename(columns={'ihs_match':'PROCESS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate facility emissions for\n",
    "dbs = ['combined_', 'Raw Material ', 'Indirect Utilities ', 'Direct Utilities ', 'Direct Process ', 'Electricity ']\n",
    "names = ['EI & CM', 'Raw Material', 'Indirect Utilities', 'Direct Utilities', 'Direct Process', 'Electricity']\n",
    "\n",
    "# Create base dataframe to use\n",
    "years = [str(i) for i in range(1978, 2051)]\n",
    "years_sigma = [year+'_sigma' for year in years]\n",
    "base_columns = ['PRODUCT', 'COUNTRY/TERRITORY', 'STATE', 'COMPANY', 'SITE', '#',\n",
    "       'ROUTE', 'TECHNOLOGY', 'LICENSOR', 'START_YR', 'COMPLEX', 'LATITUDE', 'LONGITUDE', 'PROCESS'] + years + years_sigma\n",
    "base_df = facility_min_type[base_columns]\n",
    "\n",
    "facility_mins = pd.DataFrame()\n",
    "for db, name in tqdm(zip(dbs, names)):\n",
    "    for gas in tqdm(emission_val_cols):\n",
    "        df = base_df.copy()\n",
    "        df[years] = df[years].multiply(facility_min_type[db+gas], axis='index')\n",
    "        ## Incorrect error propagation here\n",
    "        df[years_sigma] = df[years_sigma].multiply(facility_min_type[db+gas+'_sigma'], axis='index')\n",
    "        df['Gas'] = gas\n",
    "        df['Type'] = name\n",
    "        facility_mins = pd.concat((facility_mins, df), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save as parquet file for large size\n",
    "facility_mins.to_parquet(output_path+'icisFacilityEmissions_ihsAllPossible_w_uncertainties.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
